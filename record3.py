import os
import subprocess
from dotenv import load_dotenv
import streamlit as st
from datetime import datetime
import tempfile

load_dotenv()

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import whisper
except ImportError:
    subprocess.run(["pip", "install", "git+https://github.com/openai/whisper.git"])
    import whisper

try:
    import openai
except ImportError:
    subprocess.run(["pip", "install", "openai==0.28"])  # å¤ã„APIç”¨ã«å›ºå®š
    import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

st.title("éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚¢ãƒ—ãƒª")
st.write("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã£ã¦è¦ç´„ã—ã¾ã™ã€‚")

input_mode = st.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨", "æ–‡å­—èµ·ã“ã—æ¸ˆãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨"])

text_input = ""
transcription = ""
summary = ""

if input_mode == "æ–‡å­—èµ·ã“ã—æ¸ˆãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨":
    text_input = st.text_area("æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=200)
else:
    audio_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆä¾‹: .mp3, .m4a, .wavï¼‰", type=["mp3", "m4a", "wav"])
    start_time = st.text_input("é–‹å§‹æ™‚é–“ï¼ˆä¾‹: 00:00:00ï¼‰", value="00:00:00")
    end_time = st.text_input("çµ‚äº†æ™‚é–“ï¼ˆä¾‹: 00:01:00ï¼‰", value="00:01:00")
    volume = st.text_input("éŸ³å£°ãƒœãƒªãƒ¥ãƒ¼ãƒ å€ç‡ï¼ˆä¾‹: 1.5ï¼‰", value="1")

whisper_model = st.selectbox("Whisperãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼š", ["small", "medium", "large"], index=1)
mode = st.selectbox("è¦ç´„ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["åŸæ–‡ã®èª¤å­—è„±å­—ã‚’ç›´ã—ã¦ä¼šè©±ã”ã¨ã«æ”¹è¡Œè¡¨ç¤º", "å…¨ä½“ã®è¶£æ—¨ã‚’ã¾ã¨ã‚ã‚‹"])

st.subheader("ğŸ” ffmpeg ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯")
ffmpeg_check = subprocess.run(["which", "ffmpeg"], capture_output=True, text=True)
ffmpeg_path = ffmpeg_check.stdout.strip()
if ffmpeg_path:
    st.success(f"âœ… ffmpeg ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {ffmpeg_path}")
else:
    st.error("âŒ ffmpeg ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®ç’°å¢ƒã«ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")


if st.button("å®Ÿè¡Œ"):
    st.divider()

    if input_mode == "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨":
        if not all([audio_file, start_time, end_time, volume]):
            st.error("ã™ã¹ã¦ã®éŸ³å£°æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(audio_file.name)[1]) as tmp_input:
            tmp_input.write(audio_file.read())
            input_path = tmp_input.name

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_output:
            output_path = tmp_output.name

        st.write(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹: {output_path}")  # å‡ºåŠ›ãƒ‘ã‚¹ã‚’è¡¨ç¤ºã—ã¦ç¢ºèª

        command = [
            "ffmpeg", "-ss", start_time, "-to", end_time, "-i", input_path,
            "-filter:a", f"volume={volume}", output_path
        ]

        # ã“ã“ã§ã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤º
        st.write("ffmpegã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:")
        st.code(" ".join(command))

        result = subprocess.run(command, capture_output=True, text=True)

        # ã“ã“ã§æ¨™æº–å‡ºåŠ›ã¨æ¨™æº–ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹
        st.write("ffmpeg æ¨™æº–å‡ºåŠ›:")
        st.text(result.stdout)

        st.write("ffmpeg æ¨™æº–ã‚¨ãƒ©ãƒ¼:")
        st.text(result.stderr)

        if result.returncode != 0:
            st.error("âŒ ffmpeg å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.stop()
        else:
            st.success("âœ… éŸ³å£°ãƒˆãƒªãƒŸãƒ³ã‚°æˆåŠŸï¼")
            st.write(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹: {output_path}")




        if result.returncode != 0:
            st.error(f"ffmpegã‚¨ãƒ©ãƒ¼: {result.stderr}")
            st.stop()
        else:
            st.write("éŸ³å£°ãƒˆãƒªãƒŸãƒ³ã‚°æˆåŠŸ âœ…")

        st.write("æ–‡å­—èµ·ã“ã—ä¸­...")
        model = whisper.load_model(whisper_model)
        whisper_result = model.transcribe(output_path, language="ja")
        transcription = whisper_result["text"]

    else:
        transcription = text_input.strip()
        if not transcription:
            st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

    # GPTã«ã‚ˆã‚‹è¦ç´„
    system_prompt = "ã‚ãªãŸã¯æ–‡æ›¸ã®æ ¡æ­£è€…ã§ã™ã€‚"
    if mode == "åŸæ–‡ã®èª¤å­—è„±å­—ã‚’ç›´ã—ã¦ä¼šè©±ã”ã¨ã«æ”¹è¡Œè¡¨ç¤º":
        user_prompt = f"ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—æ–‡ã‚’ã€æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦æ­£ã—ã„æ—¥æœ¬èªã«ç›´ã—ã¦ãã ã•ã„ã€‚èª¤å­—è„±å­—ã€å£èªè¡¨ç¾ã€ä¸è‡ªç„¶ãªèªé †ã‚’ä¿®æ­£ã—ã€è©±è€…ãŒå¤‰ã‚ã‚‹ãŸã³ã«æ”¹è¡Œã—ã¦ãã ã•ã„ã€‚\n\n{transcription}"
    else:
        user_prompt = f"æ¬¡ã®å†…å®¹ã®å…¨ä½“ã®è¶£æ—¨ã‚’ã‚ã‹ã‚Šã‚„ã™ãçŸ­ãã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n{transcription}"

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.5
        )
        summary = response['choices'][0]['message']['content']

        st.subheader("ğŸ” æ–‡å­—èµ·ã“ã—çµæœ")
        st.text_area("æ–‡å­—èµ·ã“ã—", transcription, height=200)

        st.subheader("âœï¸ è¦ç´„çµæœ")
        st.text_area("ç”Ÿæˆã•ã‚ŒãŸè¦ç´„", summary, height=300)

        file_name = st.text_input("ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆä¾‹ï¼šresult.txtï¼‰", value="result.txt")
        if st.button("ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜"):
            combined_text = f"""ã€æ–‡å­—èµ·ã“ã—çµæœã€‘\n{transcription}\n\nã€è¦ç´„ã€‘\n{summary}\n"""
            with open(file_name, "w", encoding="utf-8") as f:
                f.write(combined_text)
            st.success(f"{file_name} ã«ä¿å­˜ã—ã¾ã—ãŸï¼")

    except Exception as e:
        st.error(f"è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

